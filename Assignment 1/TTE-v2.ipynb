{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTE-v2 Analysis and Clustering Integration Notebook\n",
    "\n",
    "This notebook presents an updated version of the TTE-v2 code with extensive documentation, improved explanations, and additional data exploration. The updates include:\n",
    "\n",
    "1. **Data Preparation and Model Training:**\n",
    "   - Loading and cleaning the input dataset.\n",
    "   - Simulating the training of the TTE-v2 model by generating risk scores.\n",
    "\n",
    "2. **Clustering Mechanism Integration:**\n",
    "   - Using K-means clustering on the generated risk scores to identify distinct subgroups (e.g., high, moderate, and low risk).\n",
    "   - Explaining why and how clustering is integrated into the analysis.\n",
    "\n",
    "3. **Visualization and Insight Generation:**\n",
    "   - Visualizing the distribution of risk scores by cluster and summarizing cluster statistics.\n",
    "\n",
    "4. **Survival Analysis Using Kaplan-Meier Estimator (Optional):**\n",
    "   - Estimating survival probabilities for different treatment groups and computing the survival difference.\n",
    "\n",
    "Each section contains detailed explanations and code examples to ensure clarity and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Model Training\n",
    "\n",
    "In this section, we load the observational dataset from `data_censored.csv`, perform basic cleaning, and simulate the training of the TTE-v2 model by generating risk scores. \n",
    "\n",
    "We then display a snapshot of the data to confirm that the loading and preprocessing steps were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configure logging to help trace the execution\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load the dataset from a CSV file and perform basic cleaning.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        # Drop rows with missing values\n",
    "        data.dropna(inplace=True)\n",
    "        logging.info(\"Data loaded and cleaned successfully from %s.\", file_path)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error loading data: %s\", e)\n",
    "        raise\n",
    "\n",
    "def train_tte_model(data):\n",
    "    \"\"\"Simulate training of the TTE-v2 model by generating a risk score for each observation.\"\n",
    "    # Here we simulate risk scores using random numbers for demonstration purposes.\n",
    "    data['risk_score'] = np.random.rand(len(data))\n",
    "    logging.info(\"TTE-v2 model simulated: risk scores generated.\")\n",
    "    return data\n",
    "\n",
    "# Load data from the CSV file (adjust the path as needed)\n",
    "data = load_data('data_censored.csv')\n",
    "\n",
    "# Simulate TTE model training\n",
    "data = train_tte_model(data)\n",
    "\n",
    "# Display the first few rows of the data to verify\n",
    "print(\"--- Data Snapshot ---\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary information about the dataset\n",
    "print(\"\\n--- Data Summary ---\")\n",
    "print(f\"Number of observations: {len(data)}\")\n",
    "if 'id' in data.columns:\n",
    "    print(f\"Number of unique patients: {data['id'].nunique()}\")\n",
    "else:\n",
    "    print(\"Column 'id' not found in the data. Check your dataset columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering Mechanism Integration\n",
    "\n",
    "After generating the risk scores, we apply K-means clustering to identify potential subgroups within the data. The rationale is as follows:\n",
    "\n",
    "- **Why Clustering?**: Clustering the risk scores can reveal whether there are distinct subpopulations (e.g., high, moderate, and low risk) within the dataset. This can provide additional insights into the heterogeneity of the predictions from the TTE-v2 model.\n",
    "\n",
    "- **How Clustering is Applied:**\n",
    "  1. We extract the `risk_score` column as the feature for clustering.\n",
    "  2. We use the K-means algorithm to partition the data into a predefined number of clusters (e.g., 3 clusters).\n",
    "  3. The resulting cluster labels are appended to the original dataset for further analysis.\n",
    "\n",
    "Below, we define a function `perform_clustering()` to carry out these steps and then apply it to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def perform_clustering(data, feature_col='risk_score', n_clusters=3, use_pca=False):\n",
    "    \"\"\"Apply K-means clustering to the specified feature in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): The dataset containing the feature.\n",
    "        feature_col (str): The column name to use for clustering.\n",
    "        n_clusters (int): The number of clusters to form.\n",
    "        use_pca (bool): Whether to apply PCA for dimensionality reduction (if needed).\n",
    "    \n",
    "    Returns:\n",
    "        data (DataFrame): The original dataset with an added 'cluster' column.\n",
    "        kmeans (KMeans): The fitted KMeans model.\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    features = data[[feature_col]].values\n",
    "    \n",
    "    # Optionally apply PCA if more than one feature is available\n",
    "    if use_pca and features.shape[1] > 1:\n",
    "        pca = PCA(n_components=2)\n",
    "        features = pca.fit_transform(features)\n",
    "        logging.info(\"PCA applied for dimensionality reduction.\")\n",
    "    \n",
    "    # Initialize and fit the K-means model\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(features)\n",
    "    data['cluster'] = clusters\n",
    "    logging.info(\"K-means clustering completed with %d clusters.\", n_clusters)\n",
    "    return data, kmeans\n",
    "\n",
    "# Apply clustering on the risk score\n",
    "data, kmeans_model = perform_clustering(data, feature_col='risk_score', n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing Clusters and Generating Insights\n",
    "\n",
    "In this section, we visualize the output of the clustering algorithm to better understand the distribution of risk scores across clusters. We:\n",
    "\n",
    "- **Plot a Boxplot:** Displays the distribution (median, quartiles, and outliers) of risk scores for each cluster.\n",
    "\n",
    "- **Print Summary Statistics:** Calculates and shows the mean, median, and standard deviation of risk scores for each cluster.\n",
    "\n",
    "- **Plot a Count Plot:** Visualizes the number of observations in each cluster.\n",
    "\n",
    "These visualizations help in identifying which cluster might represent high-risk patients versus low-risk or moderate-risk groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot risk score distribution by cluster\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='cluster', y='risk_score', data=data)\n",
    "plt.title('Risk Score Distribution Across Clusters')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Risk Score')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display summary statistics for each cluster\n",
    "cluster_summary = data.groupby('cluster')['risk_score'].agg(['mean', 'median', 'std']).reset_index()\n",
    "print(\"--- Cluster Summary Statistics ---\")\n",
    "print(cluster_summary)\n",
    "\n",
    "# Plot the count of observations per cluster\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='cluster', data=data)\n",
    "plt.title('Number of Observations per Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Survival Analysis Using Kaplan-Meier Estimator\n",
    "\n",
    "In addition to the clustering analysis, we perform survival analysis on a subset of the data to compare survival probabilities between treatment groups. \n",
    "\n",
    "The steps involved are:\n",
    "\n",
    "1. **Filter the Data:** Select observations corresponding to the first trial period (or another relevant period).\n",
    "2. **Fit Kaplan-Meier Models:** Fit separate Kaplan-Meier estimators for the treated and control groups.\n",
    "3. **Predict Survival Probabilities:** Compute the survival probabilities at defined time points.\n",
    "4. **Compute Survival Difference:** Calculate the difference in survival probabilities between the two groups and estimate confidence intervals.\n",
    "5. **Visualize the Results:** Plot the survival difference over time along with the 95% confidence intervals.\n",
    "\n",
    "This analysis provides insight into how survival probabilities differ based on treatment, which can be crucial for understanding the effect of the intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Filter the data for the first trial period (adjust the condition as needed)\n",
    "newdata = data[data[\"trial_period\"] == 1] if \"trial_period\" in data.columns else data\n",
    "\n",
    "# Define a range of follow-up times for prediction (0 to 10)\n",
    "predict_times = np.arange(0, 11)\n",
    "\n",
    "# Initialize Kaplan-Meier fitters for treated and control groups\n",
    "kmf_treated = KaplanMeierFitter()\n",
    "kmf_control = KaplanMeierFitter()\n",
    "\n",
    "# Fit the Kaplan-Meier model for the treated group\n",
    "treated_mask = newdata[\"assigned_treatment\"] == 1 if \"assigned_treatment\" in newdata.columns else np.ones(len(newdata), dtype=bool)\n",
    "kmf_treated.fit(\n",
    "    durations=newdata[treated_mask][\"followup_time\"],\n",
    "    event_observed=newdata[treated_mask][\"outcome\"],\n",
    "    label=\"Treated\"\n",
    ")\n",
    "\n",
    "# Fit the Kaplan-Meier model for the control group\n",
    "control_mask = newdata[\"assigned_treatment\"] == 0 if \"assigned_treatment\" in newdata.columns else np.zeros(len(newdata), dtype=bool)\n",
    "kmf_control.fit(\n",
    "    durations=newdata[control_mask][\"followup_time\"],\n",
    "    event_observed=newdata[control_mask][\"outcome\"],\n",
    "    label=\"Control\"\n",
    ")\n",
    "\n",
    "# Predict survival probabilities at the defined time points\n",
    "surv_prob_treated = kmf_treated.predict(predict_times)\n",
    "surv_prob_control = kmf_control.predict(predict_times)\n",
    "\n",
    "# Compute the difference in survival probabilities and estimate a basic 95% CI\n",
    "survival_diff = surv_prob_treated - surv_prob_control\n",
    "ci_lower = survival_diff - 1.96 * np.std(survival_diff)\n",
    "ci_upper = survival_diff + 1.96 * np.std(survival_diff)\n",
    "\n",
    "# Plot the survival probability difference over time\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(predict_times, survival_diff, label=\"Survival Difference\", color=\"blue\")\n",
    "plt.fill_between(predict_times, ci_lower, ci_upper, color=\"red\", alpha=0.2, label=\"95% CI\")\n",
    "plt.xlabel(\"Follow-up Time\")\n",
    "plt.ylabel(\"Survival Difference\")\n",
    "plt.title(\"Survival Probability Difference Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "- Loaded and preprocessed the input dataset from `data_censored.csv`.\n",
    "- Simulated training of the TTE-v2 model by generating risk scores.\n",
    "- Integrated a K-means clustering mechanism to identify potential subgroups in the data and provided detailed visualizations and statistics for each cluster.\n",
    "- Performed survival analysis using Kaplan-Meier estimators to compare the survival probabilities of treated and control groups.\n",
    "\n",
    "This detailed documentation and step-by-step explanation help ensure that the implementation is both clear and reproducible. Future improvements could include integrating more advanced survival models or automated report generation using tools like Sphinx or Jupyter Book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
