{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTE-v2 Analysis and Clustering Integration Notebook\n",
    "\n",
    "This notebook merges the code from **Assignment 1** with a robust Time-to-Event (TTE) analysis workflow. We:\n",
    "1. Load and prepare the dummy data (`data_censored.csv`).\n",
    "2. Demonstrate how to set up **TrialSequence** objects (`PP` and `ITT`).\n",
    "3. Simulate training of the TTE-v2 model by generating **risk scores**.\n",
    "4. Perform **K-means clustering** on these risk scores to identify subgroups.\n",
    "5. Visualize the distribution of risk scores and show additional bar plots highlighting the effect of clustering.\n",
    "6. Optionally perform a **Kaplan-Meier survival analysis** comparing treated vs. control groups.\n",
    "\n",
    "Throughout this notebook, each step is documented to ensure clarity, reproducibility, and a complete demonstration of how the TTE-v2 approach integrates with clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "We first define our `TrialSequence` class, which mimics the structure from the R package in Assignment 1. We also create directories to save output models if needed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import tempfile\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.switch_weight_model = None\n",
    "        self.censor_weight_model = None\n",
    "        # These are placeholders for demonstration.\n",
    "        self.weight_models = {}  # for storing fitted weight models\n",
    "        self.expansion = None    # for storing expansion details\n",
    "\n",
    "    def set_data(self, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "        \"\"\"Assign dataset columns to the trial object.\"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.data.rename(\n",
    "            columns={\n",
    "                id_col: \"id\",\n",
    "                period_col: \"period\",\n",
    "                treatment_col: \"treatment\",\n",
    "                outcome_col: \"outcome\",\n",
    "                eligible_col: \"eligible\",\n",
    "            }, \n",
    "            inplace=True\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def set_switch_weight_model(self, numerator, denominator, save_path):\n",
    "        \"\"\"Placeholder for setting a switch weight model (PP).\"\"\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.switch_weight_model = {\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"model_fitter\": \"stats_glm_logit\",\n",
    "            \"save_path\": save_path\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def set_censor_weight_model(self, censor_event, numerator, denominator, pool_models, save_path):\n",
    "        \"\"\"Placeholder for setting a censor weight model.\"\"\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.censor_weight_model = {\n",
    "            \"censor_event\": censor_event,\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"pool_models\": pool_models,\n",
    "            \"model_fitter\": \"stats_glm_logit\",\n",
    "            \"save_path\": save_path\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def calculate_weights(self):\n",
    "        \"\"\"Placeholder to simulate weight calculation.\"\"\"\n",
    "        logging.info(\"Weight models not truly fitted. This is a placeholder.\")\n",
    "        # In a real scenario, you'd fit logistic models for numerator/denominator.\n",
    "        return self\n",
    "\n",
    "    def set_outcome_model(self, adjustment_terms=None):\n",
    "        \"\"\"Placeholder for setting outcome model, possibly with adjustment terms.\"\"\"\n",
    "        logging.info(\"Outcome model setup with terms: %s.\", adjustment_terms)\n",
    "        return self\n",
    "\n",
    "    def set_expansion_options(self, output=\"datatable\", chunk_size=500):\n",
    "        \"\"\"Placeholder for specifying expansion options.\"\"\"\n",
    "        self.expansion = {\n",
    "            \"output\": output,\n",
    "            \"chunk_size\": chunk_size,\n",
    "            \"censor_at_switch\": False,\n",
    "            \"first_period\": 0,\n",
    "            \"last_period\": float('inf')\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def expand_trials(self):\n",
    "        \"\"\"Placeholder for creating sequence of target trials data.\"\"\"\n",
    "        logging.info(\"Expanding trials (placeholder).\")\n",
    "        # Real logic would expand the dataset by trial period, etc.\n",
    "        return self\n",
    "\n",
    "    def load_expanded_data(self, seed=None, p_control=1.0):\n",
    "        \"\"\"Placeholder for loading or sampling from expanded data.\"\"\"\n",
    "        logging.info(\n",
    "            \"Loading expanded data with seed=%s, p_control=%.2f (placeholder).\",\n",
    "            str(seed), p_control\n",
    "        )\n",
    "        # Real logic would do subsetting/sampling here.\n",
    "        return self\n",
    "\n",
    "    def fit_msm(self, weight_cols=None, modify_weights=None):\n",
    "        \"\"\"Placeholder for fitting a marginal structural model.\"\"\"\n",
    "        logging.info(\"Fitting MSM (placeholder). Weight columns: %s.\", weight_cols)\n",
    "        # Real logic would fit a logistic or other model.\n",
    "        return self\n",
    "\n",
    "    def show_weight_models(self):\n",
    "        \"\"\"Placeholder for displaying weight model summaries.\"\"\"\n",
    "        print(\"Weight Models for Informative Censoring (placeholder).\")\n",
    "        # Real logic would print details of fitted weight models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directories for trial_pp and trial_itt (as in Assignment 1)\n",
    "We replicate the R code's approach of creating directories in a temporary folder. In a real scenario, these could be replaced with persistent paths."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "trial_pp_dir = os.path.join(tempfile.gettempdir(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "trial_itt_dir = os.path.join(tempfile.gettempdir(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "We load `data_censored.csv` (a dummy dataset) as in Assignment 1, then instantiate `trial_pp` (Per-Protocol) and `trial_itt` (Intention-to-Treat)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "print(\"--- Loaded data_censored.csv (head) ---\")\n",
    "print(data_censored.head())\n",
    "\n",
    "# Per-protocol\n",
    "trial_pp = TrialSequence(estimand=\"PP\").set_data(\n",
    "    data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "# Intention-to-treat\n",
    "trial_itt = TrialSequence(estimand=\"ITT\").set_data(\n",
    "    data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Trial ITT Data (head) ---\")\n",
    "print(trial_itt.data.head())\n",
    "print(f\"Number of observations: {len(trial_itt.data)}\")\n",
    "print(f\"Number of unique patients: {trial_itt.data['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Weight Models and Censoring (Placeholder)\n",
    "For completeness, we mimic the steps from Assignment 1, setting up switch and censor weight models. (In a real scenario, these would be fitted with logistic regression.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "trial_pp = trial_pp.set_switch_weight_model(\n",
    "    numerator=\"treatment ~ age\",\n",
    "    denominator=\"treatment ~ age + x1 + x3\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "\n",
    "print(\"\\n--- Switch Weight Model (PP) ---\")\n",
    "print(f\"Numerator: {trial_pp.switch_weight_model['numerator']}\")\n",
    "print(f\"Denominator: {trial_pp.switch_weight_model['denominator']}\")\n",
    "\n",
    "# Censor weight model for PP\n",
    "trial_pp = trial_pp.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"1 - censored ~ x2\",\n",
    "    denominator=\"1 - censored ~ x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"censor_models\")\n",
    ")\n",
    "\n",
    "print(\"\\n--- Censor Weight Model (PP) ---\")\n",
    "print(f\"Numerator: {trial_pp.censor_weight_model['numerator']}\")\n",
    "print(f\"Denominator: {trial_pp.censor_weight_model['denominator']}\")\n",
    "\n",
    "# Censor weight model for ITT\n",
    "trial_itt = trial_itt.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"1 - censored ~ x2\",\n",
    "    denominator=\"1 - censored ~ x2 + x1\",\n",
    "    pool_models=\"numerator\",  # Numerator model is pooled across arms\n",
    "    save_path=os.path.join(trial_itt_dir, \"censor_models\")\n",
    ")\n",
    "print(\"\\n--- Censor Weight Model (ITT) ---\")\n",
    "print(f\"Numerator: {trial_itt.censor_weight_model['numerator']}\")\n",
    "print(f\"Denominator: {trial_itt.censor_weight_model['denominator']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculate Weights (Placeholder)\n",
    "We call `calculate_weights()` to mimic the weighting procedure. This is a stub here."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "trial_pp.calculate_weights()\n",
    "trial_itt.calculate_weights()\n",
    "\n",
    "# We can also show weight models, though they're placeholders.\n",
    "print(\"\\n--- Show Weight Models (PP) ---\")\n",
    "trial_pp.show_weight_models()\n",
    "print(\"\\n--- Show Weight Models (ITT) ---\")\n",
    "trial_itt.show_weight_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Specify Outcome Model and Expand Trials (Placeholder)\n",
    "These steps replicate the R code from Assignment 1 but do not perform real expansions or outcome model fitting."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "trial_pp.set_outcome_model()\n",
    "trial_itt.set_outcome_model(adjustment_terms=[\"x2\"])\n",
    "\n",
    "# Set expansion options\n",
    "trial_pp.set_expansion_options(output=\"datatable\", chunk_size=500)\n",
    "trial_itt.set_expansion_options(output=\"datatable\", chunk_size=500)\n",
    "\n",
    "# Expand trials\n",
    "trial_pp.expand_trials()\n",
    "trial_itt.expand_trials()\n",
    "\n",
    "print(\"\\n--- Trial PP expansion details ---\")\n",
    "print(trial_pp.expansion)\n",
    "\n",
    "print(\"\\n--- Trial ITT expansion details ---\")\n",
    "print(trial_itt.expansion)\n",
    "\n",
    "# Optionally load expanded data with sampling\n",
    "trial_itt.load_expanded_data(seed=1234, p_control=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simulate TTE-v2 Model Training and Generate Risk Scores\n",
    "\n",
    "Here we simulate the TTE-v2 model by generating a `risk_score` column. This is purely for demonstration. In a real scenario, you'd fit an actual time-to-event model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_tte_model(data):\n",
    "    \"\"\"Simulate training of the TTE-v2 model by generating a risk score for each observation.\"\"\"\n",
    "    data['risk_score'] = np.random.rand(len(data))\n",
    "    logging.info(\"TTE-v2 model simulated: risk scores generated.\")\n",
    "    return data\n",
    "\n",
    "# Apply the simulated training to the ITT data, for example.\n",
    "trial_itt.data = train_tte_model(trial_itt.data)\n",
    "\n",
    "print(\"\\n--- Trial ITT Data with Risk Score (head) ---\")\n",
    "print(trial_itt.data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clustering Mechanism Integration\n",
    "\n",
    "After generating the risk scores, we apply **K-means clustering** to uncover potential subgroups within the data.\n",
    "\n",
    "**Rationale**:\n",
    "- Clustering can reveal subpopulations (e.g., high, moderate, low risk). \n",
    "- This can inform how we tailor interventions or interpret TTE results.\n",
    "\n",
    "**Implementation**:\n",
    "1. Extract the `risk_score` column.\n",
    "2. Use K-means to partition the data (e.g., 3 clusters).\n",
    "3. Append cluster labels to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def perform_clustering(data, feature_col='risk_score', n_clusters=3, use_pca=False):\n",
    "    \"\"\"Apply K-means clustering to the specified feature in the dataset.\"\"\"\n",
    "    features = data[[feature_col]].values\n",
    "\n",
    "    if use_pca and features.shape[1] > 1:\n",
    "        pca = PCA(n_components=2)\n",
    "        features = pca.fit_transform(features)\n",
    "        logging.info(\"PCA applied for dimensionality reduction.\")\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(features)\n",
    "    data['cluster'] = clusters\n",
    "    logging.info(\"K-means clustering completed with %d clusters.\", n_clusters)\n",
    "    return data, kmeans\n",
    "\n",
    "# Perform clustering on the ITT data's risk score\n",
    "trial_itt.data, kmeans_model = perform_clustering(trial_itt.data, feature_col='risk_score', n_clusters=3)\n",
    "\n",
    "print(\"\\n--- Clustered ITT Data (head) ---\")\n",
    "print(trial_itt.data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing Clusters and Generating Insights\n",
    "\n",
    "We visualize the clustering results to interpret the risk profiles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='cluster', y='risk_score', data=trial_itt.data)\n",
    "plt.title('Risk Score Distribution Across Clusters')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Risk Score')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics per cluster\n",
    "cluster_summary = trial_itt.data.groupby('cluster')['risk_score'].agg(['mean', 'median', 'std']).reset_index()\n",
    "print(\"--- Cluster Summary Statistics ---\")\n",
    "print(cluster_summary)\n",
    "\n",
    "# Count of observations per cluster\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='cluster', data=trial_itt.data)\n",
    "plt.title('Number of Observations per Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Visualization: Effect of Clustering Implementation\n",
    "\n",
    "To further illustrate the impact of clustering, we create bar plots:\n",
    "- **Mean Risk Score by Cluster**: Shows average risk score (with standard deviation as error bars).\n",
    "- **Event Rate by Cluster**: Proportion of events (`outcome`) in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ensure 'outcome' is numeric. If it's not, convert it.\n",
    "# If 'outcome' is 0/1, we can treat it as numeric to compute means.\n",
    "if trial_itt.data['outcome'].dtype != 'int' and trial_itt.data['outcome'].dtype != 'float':\n",
    "    # Attempt to convert outcome to numeric if it's not.\n",
    "    trial_itt.data['outcome'] = pd.to_numeric(trial_itt.data['outcome'], errors='coerce')\n",
    "    trial_itt.data.dropna(subset=['outcome'], inplace=True)\n",
    "\n",
    "# Compute mean risk score and standard deviation per cluster\n",
    "cluster_stats = trial_itt.data.groupby('cluster')['risk_score'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Compute event rate per cluster (assuming 'outcome' is 0 or 1)\n",
    "event_rate = trial_itt.data.groupby('cluster')['outcome'].mean().reset_index()\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar plot for mean risk score\n",
    "sns.barplot(x='cluster', y='mean', data=cluster_stats, ax=axes[0], capsize=0.1)\n",
    "axes[0].set_title('Mean Risk Score by Cluster')\n",
    "axes[0].set_xlabel('Cluster')\n",
    "axes[0].set_ylabel('Mean Risk Score')\n",
    "\n",
    "# Add error bars (std) manually\n",
    "for index, row in cluster_stats.iterrows():\n",
    "    axes[0].errorbar(\n",
    "        row['cluster'],\n",
    "        row['mean'],\n",
    "        yerr=row['std'],\n",
    "        fmt='none',\n",
    "        c='black'\n",
    "    )\n",
    "\n",
    "# Bar plot for event rate by cluster\n",
    "sns.barplot(x='cluster', y='outcome', data=event_rate, ax=axes[1])\n",
    "axes[1].set_title('Event Rate (Outcome) by Cluster')\n",
    "axes[1].set_xlabel('Cluster')\n",
    "axes[1].set_ylabel('Event Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Survival Analysis Using Kaplan-Meier Estimator (Optional)\n",
    "\n",
    "We optionally compare survival probabilities between treated and control groups using the Kaplan-Meier approach. This step uses `lifelines`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Filter data for the first trial period (if available)\n",
    "if 'period' in trial_itt.data.columns:\n",
    "    newdata = trial_itt.data[trial_itt.data['period'] == 1].copy()\n",
    "else:\n",
    "    newdata = trial_itt.data.copy()\n",
    "\n",
    "# Ensure followup_time, assigned_treatment columns exist or create them if needed\n",
    "# For demonstration, we create them if they do not exist.\n",
    "if 'followup_time' not in newdata.columns:\n",
    "    # Suppose we simulate a followup_time as row index, just for demonstration\n",
    "    newdata['followup_time'] = range(len(newdata))\n",
    "\n",
    "if 'assigned_treatment' not in newdata.columns:\n",
    "    # Suppose we treat 'treatment' as 'assigned_treatment'\n",
    "    newdata['assigned_treatment'] = newdata['treatment']\n",
    "\n",
    "kmf_treated = KaplanMeierFitter()\n",
    "kmf_control = KaplanMeierFitter()\n",
    "\n",
    "# Fit the Kaplan-Meier model for the treated group\n",
    "treated_mask = newdata['assigned_treatment'] == 1\n",
    "kmf_treated.fit(\n",
    "    durations=newdata[treated_mask]['followup_time'],\n",
    "    event_observed=newdata[treated_mask]['outcome'],\n",
    "    label=\"Treated\"\n",
    ")\n",
    "\n",
    "# Fit the Kaplan-Meier model for the control group\n",
    "control_mask = newdata['assigned_treatment'] == 0\n",
    "kmf_control.fit(\n",
    "    durations=newdata[control_mask]['followup_time'],\n",
    "    event_observed=newdata[control_mask]['outcome'],\n",
    "    label=\"Control\"\n",
    ")\n",
    "\n",
    "# Predict survival probabilities at time points 0 to 10\n",
    "predict_times = range(0, 11)\n",
    "surv_prob_treated = kmf_treated.predict(predict_times)\n",
    "surv_prob_control = kmf_control.predict(predict_times)\n",
    "\n",
    "# Compute difference\n",
    "survival_diff = surv_prob_treated - surv_prob_control\n",
    "diff_std = survival_diff.std()\n",
    "ci_lower = survival_diff - 1.96 * diff_std\n",
    "ci_upper = survival_diff + 1.96 * diff_std\n",
    "\n",
    "# Plot the survival difference\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(predict_times, survival_diff, label=\"Survival Difference\", color=\"blue\")\n",
    "plt.fill_between(predict_times, ci_lower, ci_upper, color=\"red\", alpha=0.2, label=\"95% CI\")\n",
    "plt.xlabel(\"Follow-up Time\")\n",
    "plt.ylabel(\"Survival Difference\")\n",
    "plt.title(\"Survival Probability Difference Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This unified notebook shows how we:\n",
    "1. **Load** the dummy data (`data_censored.csv`) from Assignment 1.\n",
    "2. **Set up** `TrialSequence` objects (`PP` and `ITT`).\n",
    "3. **Simulate** a TTE-v2 model by generating risk scores.\n",
    "4. **Cluster** those risk scores via K-means and visualize them with boxplots, counts, and additional bar charts.\n",
    "5. **Optionally** perform Kaplan-Meier survival analysis.\n",
    "\n",
    "The bar plots demonstrate the **effect** of the clustering implementation:\n",
    "- One plot shows the **mean risk score** (with standard deviation) for each cluster.\n",
    "- Another shows the **event rate** (the mean of `outcome`) per cluster.\n",
    "\n",
    "This approach clarifies how subgroups differ in predicted risk and observed outcomes, illustrating the **practical** impact of our clustering step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
