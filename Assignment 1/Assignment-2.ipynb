{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Clustering with Sessa Empirical Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the Journals about the Sessa Empirical Estimator.\n",
    "\n",
    "prompt: </br>\n",
    "Our professor for Data Analysis gave us an assignment for clustering with Sessa Empirical Estimator. The first step is to read the journals about the Sessa Empirical Estimator. [journals attached in prompt]\n",
    "\n",
    "ChatGPT response: </br>\n",
    "The Sessa Empirical Estimator (SEE) is a data-driven method designed to compute the duration of pharmacological prescriptions when information on the prescribed dose and daily consumption is missing or incomplete. It uses a k-means clustering algorithm to analyze temporal distances between filled prescriptions and estimate prescription durations.\n",
    "\n",
    "To get a deeper understanding of the Sessa Empirical Estimator and its application in clustering, I recommend focusing on the following points from the uploaded journals:\n",
    "\n",
    "1. **Definition and Purpose of SEE**  \n",
    "   - It helps determine drug exposure status when actual prescription durations are not available.\n",
    "   - It is useful in pharmacoepidemiological studies, particularly for assessing persistence, effectiveness, or safety of treatments.\n",
    "\n",
    "2. **Methodology of SEE**  \n",
    "   - Uses k-means clustering to classify temporal distances between prescription refills.\n",
    "   - Filters out artificially long gaps caused by patients who restart medication after a long pause.\n",
    "   - Computes the empirical cumulative distribution function (ECDF) to determine the most probable prescription duration.\n",
    "\n",
    "3. **Applications of SEE in Data Analysis**  \n",
    "   - Applied in real-world healthcare data, particularly for evaluating adherence to antihypertensive and antiseizure medications.\n",
    "   - Used in large-scale Danish healthcare registers to assess co-exposure to medications.\n",
    "   - Compared with traditional Researcher-Defined Duration (RDD) methods, showing higher sensitivity.\n",
    "\n",
    "4. **Performance and Accuracy**  \n",
    "   - Demonstrated 96% accuracy and sensitivity when tested on simulated data.\n",
    "   - Real-world applications showed sensitivity ranging from 78% to 95%, depending on the medication.\n",
    "\n",
    "Would you like a summarized report or more details on how to implement clustering with SEE in your assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert the R codes into Python Codes (use jupyter notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt: </br>\n",
    "Our next instruction is to convert R code into python using Jupyter Notebook. Can you teach us how to do it? [Attached SEE.R]\n",
    "\n",
    "ChatGPT response: </br>\n",
    "To convert the provided R code into Python using Jupyter Notebook, follow these steps:\n",
    "\n",
    "### **Step 1: Understanding the R Code**\n",
    "The R script you uploaded:\n",
    "- Uses the `AdhereR`, `dplyr`, `plyr`, `lubridate`, `data.table`, and `stats` packages.\n",
    "- Reads a dataset (`tidy`) and filters it based on an ATC drug code (`arg1`).\n",
    "- Calculates empirical cumulative distribution functions (ECDF) for prescription durations.\n",
    "- Applies k-means clustering to categorize drug refill intervals.\n",
    "- Assigns a predicted duration based on cluster medians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Setting Up Python and Required Libraries**\n",
    "You need the following Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Converting Key R Functions to Python**\n",
    "Below is a basic conversion of the R function See() into Python:\n",
    "\n",
    "**1. Load and Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_samples=1 should be >= n_clusters=2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m medA_result \u001b[38;5;241m=\u001b[39m \u001b[43msee_python\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(medA_result)\n",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m, in \u001b[0;36msee_python\u001b[1;34m(drug_code)\u001b[0m\n\u001b[0;32m     30\u001b[0m best_cluster_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Placeholder; would use silhouette analysis\u001b[39;00m\n\u001b[0;32m     31\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mbest_cluster_num, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m df_ecdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Assign median durations from clusters\u001b[39;00m\n\u001b[0;32m     35\u001b[0m cluster_medians \u001b[38;5;241m=\u001b[39m df_ecdf\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[1;32mc:\\Users\\jrudu\\Documents\\Code\\Data Anal\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1064\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \n\u001b[0;32m   1044\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;124;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32mc:\\Users\\jrudu\\Documents\\Code\\Data Anal\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jrudu\\Documents\\Code\\Data Anal\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1464\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m \n\u001b[0;32m   1430\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1454\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m   1455\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1456\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1461\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1462\u001b[0m )\n\u001b[1;32m-> 1464\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m   1467\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\jrudu\\Documents\\Code\\Data Anal\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1404\u001b[0m, in \u001b[0;36mKMeans._check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m-> 1404\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_n_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_algorithm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\n\u001b[0;32m   1407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melkan\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jrudu\\Documents\\Code\\Data Anal\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:871\u001b[0m, in \u001b[0;36m_BaseKMeans._check_params_vs_input\u001b[1;34m(self, X, default_n_init)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, default_n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# n_clusters\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters:\n\u001b[1;32m--> 871\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    872\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be >= n_clusters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m         )\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# tol\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tol \u001b[38;5;241m=\u001b[39m _tolerance(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol)\n",
      "\u001b[1;31mValueError\u001b[0m: n_samples=1 should be >= n_clusters=2."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulated dataset equivalent to `tidy`\n",
    "tidy = pd.DataFrame({\n",
    "    \"pnr\": [1, 2, 1, 3, 2, 3, 1, 3],  \n",
    "    \"eksd\": pd.to_datetime([\"2023-01-01\", \"2023-02-01\", \"2023-02-15\", \"2023-03-01\", \"2023-03-15\", \"2023-04-01\", \"2023-04-15\", \"2023-05-01\"]),\n",
    "    \"perday\": [1, 1, 2, 1, 2, 1, 1, 1],  \n",
    "    \"ATC\": [\"medA\", \"medB\", \"medA\", \"medB\", \"medA\", \"medB\", \"medA\", \"medB\"],\n",
    "    \"dur_original\": [30, 15, 20, 40, 35, 25, 50, 30]  \n",
    "})\n",
    "\n",
    "# Function equivalent to `See()` in R\n",
    "def see_python(drug_code):\n",
    "    df = tidy[tidy[\"ATC\"] == drug_code].copy()\n",
    "    df = df.sort_values([\"pnr\", \"eksd\"])\n",
    "    df[\"prev_eksd\"] = df.groupby(\"pnr\")[\"eksd\"].shift(1)\n",
    "    df = df.dropna()  \n",
    "    df[\"event_interval\"] = (df[\"eksd\"] - df[\"prev_eksd\"]).dt.days  \n",
    "\n",
    "    # ECDF calculation\n",
    "    x = np.sort(df[\"event_interval\"])\n",
    "    y = np.arange(1, len(x) + 1) / len(x)\n",
    "    \n",
    "    # Keep 80% ECDF\n",
    "    df_ecdf = pd.DataFrame({\"x\": x, \"y\": y})\n",
    "    df_ecdf = df_ecdf[df_ecdf[\"y\"] <= 0.8]\n",
    "\n",
    "    # Clustering\n",
    "    data_scaled = np.log(df_ecdf[\"x\"]).values.reshape(-1, 1)\n",
    "    best_cluster_num = 2  # Placeholder; would use silhouette analysis\n",
    "    kmeans = KMeans(n_clusters=best_cluster_num, random_state=1234)\n",
    "    df_ecdf[\"cluster\"] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "    # Assign median durations from clusters\n",
    "    cluster_medians = df_ecdf.groupby(\"cluster\")[\"x\"].median().to_dict()\n",
    "    df[\"Cluster\"] = kmeans.predict(np.log(df[\"event_interval\"]).values.reshape(-1, 1))\n",
    "    df[\"Median\"] = df[\"Cluster\"].map(cluster_medians)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "medA_result = see_python(\"medA\")\n",
    "print(medA_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
